{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize OpenAI API \n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def fetch_website_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Remove script, style, header, footer, and navigation elements\n",
    "        for element in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Find the main content\n",
    "        main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content')\n",
    "        \n",
    "        if main_content:\n",
    "            text = main_content.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            text = soup.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        # Further clean up the text\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        text = '\\n'.join(line for line in lines if line)\n",
    "        \n",
    "        return text[:8000]  # Increased to 8000 characters for more context\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching website content: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_content(content, url):\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are an expert data analyst specialized in content analysis and keyword extraction for business research. Your task is to analyze the given content and extract relevant information to categorize the source. The content given is parsed from websites, It may have irrelevant stuff that you need to ignore. Your audience is business researchers who will use this information for market analysis and reports.\n",
    "\n",
    "        Provide your answers in the following format:\n",
    "\n",
    "        1. Sector/Area: (Main industry or area of focus)\n",
    "        2. Sub-Sector: (More specific category within the Sector/Area)\n",
    "        3. Source name: (Name of the organization or database providing the information)\n",
    "        4. Description: (2-3 sentences summarizing what kind of data or information the source provides)        \n",
    "        5. Years: (The range of years the data covers, in the format \"YYYY; YYYY; YYYY\" for specific years or \"YYYY-YYYY\" for ranges) If not specified, use \"Not specified.\" ONLY.\n",
    "        6. Tags: (At least 30 relevant keywords and phrases, separated by semicolons. Include a mix of general and specific terms, synonyms, related terms, and both short-tail and long-tail keywords. Consider different user intents such as informational, navigational, and transactional.)\n",
    "\n",
    "        Guidelines:\n",
    "        - For Sector/Area and Sub-Sector, be specific but not overly narrow.\n",
    "        - The Description should be informative but concise, focusing on the type of data available.\n",
    "        - Tags should be comprehensive and relevant for search and categorization purposes.\n",
    "        - For Years, if specific years are mentioned, list them individually. If a range is given, use the range format.\n",
    "        - Avoid including irrelevant information or speculation.\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    conversation = [\n",
    "        system_prompt,\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze the following content from {url} and provide the requested information:\\n\\n{content}\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0.1,\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    lines = response.split('\\n')\n",
    "    result = {}\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.split('.', 1)[-1].strip()  # Remove numbering and strip\n",
    "            result[key] = value.strip()\n",
    "    \n",
    "    # Process Years field\n",
    "    if 'Years' in result:\n",
    "        years = result['Years']\n",
    "        # If it's a range, keep it as is\n",
    "        if '-' in years:\n",
    "            result['Years'] = years\n",
    "        else:\n",
    "            # If it's a list of years, ensure they are separated by semicolons\n",
    "            years = re.findall(r'\\d{4}', years)\n",
    "            result['Years'] = '; '.join(years)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def check_link_exists(df, link):\n",
    "    return link in df['Link'].values\n",
    "\n",
    "def process_link(df, link):\n",
    "    if check_link_exists(df, link):\n",
    "        return {\"error\": \"Link already exists in the database\"}\n",
    "\n",
    "    content = fetch_website_content(link)\n",
    "    if not content:\n",
    "        return {\"error\": \"Failed to fetch website content\"}\n",
    "\n",
    "    llm_response = analyze_content(content, link)\n",
    "    parsed_response = parse_llm_response(llm_response)\n",
    "    parsed_response['link'] = link\n",
    "\n",
    "    return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PA classification', 'Sector/Area', 'Sub-Sector', 'Source name',\n",
       "       'Description', 'Type (General DB, specialized, ...)', 'Free/Paid?',\n",
       "       'Geography', 'Regional data', 'Country data',\n",
       "       'Frequency cover harmonized for all geos ? ', 'Frequency ', 'Years',\n",
       "       'Tags', 'Format ', 'Reliability score (1-10) ', 'Link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Youssef Moutaouakkil\\Desktop\\Github\\BCG_Search_Website\\bcg-knowledge-search-tool\\Backend\\Database.xlsx')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.oica.net\n",
      ">\n",
      "Sales Statistics\n",
      "Global Sales Statistics 2019 – 2023\n",
      "SALES OF NEW VEHICLES 2019-2023\n",
      "/\n",
      "Passengers Cars\n",
      "/\n",
      "Commercial vehicles\n",
      "/\n",
      "All vehicles\n",
      "Overview\n",
      "All the data available at OICA are included here.\n",
      "For more details, please contact the respective countries or the individual OICA member associations directly\n",
      ".\n",
      "The OICA secretariat does not have any further data.\n",
      "These data are gathered in cooperation with\n",
      "Ward’s\n",
      "(for the American Continent) and\n",
      "Fourin\n",
      "(for the Asian Continent).\n",
      "Definitions\n"
     ]
    }
   ],
   "source": [
    "#Let's testt the functions one by one , link : https://www.oica.net/category/sales-statistics/\n",
    "\n",
    "# Fetch website content\n",
    "url = \"https://www.oica.net/category/sales-statistics/\"\n",
    "content = fetch_website_content(url)\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = analyze_content(content, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sector/Area: Automotive Industry\n",
      "2. Sub-Sector: Automotive Sales Statistics\n",
      "3. Source name: International Organization of Motor Vehicle Manufacturers (OICA)\n",
      "4. Description: OICA provides global sales statistics for new vehicles, including passenger cars, commercial vehicles, and the total of all vehicles. The data is collected in cooperation with Ward's for the American continent and Fourin for the Asian continent.\n",
      "5. Years: 2019-2023\n",
      "6. Tags: OICA; global vehicle sales; automotive sales data; passenger cars sales statistics; commercial vehicles sales statistics; vehicle sales trends; automotive industry analysis; new vehicle sales; automotive market research; Ward's automotive data; Fourin automotive data; automotive sales reports; vehicle sales data; car sales statistics; truck sales statistics; automotive sales figures; market analysis automotive; international vehicle sales; automotive sales tracking; sales of new vehicles; automotive sector statistics; vehicle industry sales data; car market sales data; commercial vehicle market trends; automotive sales information; global car sales report; vehicle sales by continent; automotive business research; OICA sales statistics; automotive market data; vehicle sales overview; automotive sales cooperation; American automotive market; Asian automotive market.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sector/Area': 'Automotive Industry',\n",
       " 'Sub-Sector': 'Automotive Sales Statistics',\n",
       " 'Source name': 'International Organization of Motor Vehicle Manufacturers (OICA)',\n",
       " 'Description': \"OICA provides global sales statistics for new vehicles, including passenger cars, commercial vehicles, and the total of all vehicles. The data is collected in cooperation with Ward's for the American continent and Fourin for the Asian continent.\",\n",
       " 'Years': '2019-2023',\n",
       " 'Tags': \"OICA; global vehicle sales; automotive sales data; passenger cars sales statistics; commercial vehicles sales statistics; vehicle sales trends; automotive industry analysis; new vehicle sales; automotive market research; Ward's automotive data; Fourin automotive data; automotive sales reports; vehicle sales data; car sales statistics; truck sales statistics; automotive sales figures; market analysis automotive; international vehicle sales; automotive sales tracking; sales of new vehicles; automotive sector statistics; vehicle industry sales data; car market sales data; commercial vehicle market trends; automotive sales information; global car sales report; vehicle sales by continent; automotive business research; OICA sales statistics; automotive market data; vehicle sales overview; automotive sales cooperation; American automotive market; Asian automotive market.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_llm_response(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Link already exists in the database'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check link exists with :  C:\\Users\\Youssef Moutaouakkil\\Desktop\\Github\\BCG_Search_Website\\bcg-knowledge-search-tool\\Backend\\Database.xlsx\n",
    "df = pd.read_excel(r\"C:\\Users\\Youssef Moutaouakkil\\Desktop\\Github\\BCG_Search_Website\\bcg-knowledge-search-tool\\Backend\\Database.xlsx\")\n",
    "link = \"https://www.oica.net/category/sales-statistics/\"\n",
    "\n",
    "\n",
    "process_link(df, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database - Eurostat\n",
      "Structural business statistics\n",
      "Database\n",
      "Site Map\n",
      "Data navigation tree\n",
      "Hidden\n",
      "Close\n",
      "Your feedback was sent\n",
      "Thank you for your feedback.\n",
      "Thank you for the information. We will investigate the issue.\n",
      "Was this page useful?\n",
      "Yes\n",
      "✓\n",
      "No\n",
      "If you do not wish to provide more detailed feedback, please just click on the “Submit” button to send your response.\n",
      "Click this radio box.\n",
      "What type of issue would you like to report?\n",
      "(Optional)\n",
      "Select type\n",
      "There is a technical problem with this page\n",
      "I cannot find the information I am looking for\n",
      "Other\n",
      "Show / hide list\n",
      "Enter your name\n",
      "Please describe the issue\n",
      "(Optional)\n",
      "Please do not include any personal information\n",
      "300\n",
      "/300 characters remaining\n",
      "I accept the terms & conditions.\n",
      "Submit\n"
     ]
    }
   ],
   "source": [
    "link = \"https://ec.europa.eu/eurostat/web/structural-business-statistics/database\"\n",
    "\n",
    "# let's look at the parsing of the website first\n",
    "content = fetch_website_content(link)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sector/Area: Economics and Statistics\n",
      "2. Sub-Sector: Structural Business Statistics\n",
      "3. Source name: Eurostat\n",
      "4. Description: Eurostat's database provides comprehensive statistics on the structure, conduct, and performance of businesses across the European Union. It includes data on business demographics, financial operations, and sectoral performance, which can be used for market analysis and economic research.\n",
      "5. Years: Not specified.\n",
      "6. Tags: Eurostat; Structural Business Statistics; European Union; Business Demographics; Financial Operations; Sectoral Performance; Market Analysis; Economic Research; Business Data; EU Statistics; Business Conduct; Business Performance; Statistical Database; Business Sector Data; Economic Data; Business Research; Business Statistics; Eurostat Database; Economic Analysis; Industry Analysis; Business Operations; Company Statistics; Business Environment; European Market Data; Business Trends; Economic Indicators; Business Analysis; Statistical Analysis; Business Metrics; Economic Performance; Business Sector Analysis; Market Research.\n"
     ]
    }
   ],
   "source": [
    "text_2 = analyze_content(content, link)\n",
    "\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# curl this website to get the content (without the function to see what it looks like) : \"https://ec.europa.eu/eurostat/web/structural-business-statistics/database\"\n",
    "\n",
    "url = \"https://ec.europa.eu/eurostat/web/structural-business-statistics/database\"\n",
    "response = requests.get(url)\n",
    "content = response.text\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2' coro=<Connection.run() done, defined at c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\site-packages\\playwright\\_impl\\_connection.py:265> exception=NotImplementedError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\site-packages\\playwright\\_impl\\_connection.py\", line 272, in run\n",
      "    await self._transport.connect()\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\site-packages\\playwright\\_impl\\_transport.py\", line 133, in connect\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\site-packages\\playwright\\_impl\\_transport.py\", line 120, in connect\n",
      "    self._proc = await asyncio.create_subprocess_exec(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\asyncio\\subprocess.py\", line 224, in create_subprocess_exec\n",
      "    transport, protocol = await loop.subprocess_exec(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\asyncio\\base_events.py\", line 1744, in subprocess_exec\n",
      "    transport = await self._make_subprocess_transport(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Youssef Moutaouakkil\\.conda\\envs\\notebooksBaisc\\Lib\\asyncio\\base_events.py\", line 524, in _make_subprocess_transport\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching website content: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def fetch_website_playwright(url):\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch()\n",
    "            page = await browser.new_page()\n",
    "            await page.goto(url)\n",
    "            \n",
    "            # Wait for the content to load\n",
    "            await page.wait_for_load_state('networkidle')\n",
    "            \n",
    "            # Get the full HTML content\n",
    "            content = await page.content()\n",
    "            \n",
    "            await browser.close()\n",
    "        \n",
    "        # Parse the content with BeautifulSoup\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        # Remove script and style elements\n",
    "        for element in soup([\"script\", \"style\"]):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Get text from the body\n",
    "        text = soup.body.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        # Further clean up the text\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        text = '\\n'.join(line for line in lines if line)\n",
    "        \n",
    "        return text[:10000]  # Increased to 10000 characters for more context\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching website content: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = \"https://ec.europa.eu/eurostat/web/structural-business-statistics/database\"\n",
    "content = asyncio.run(fetch_website_playwright(url))\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching website content: 'PlaywrightContextManager' object does not support the asynchronous context manager protocol\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youssef Moutaouakkil\\AppData\\Local\\Temp\\ipykernel_383160\\2461292002.py:2: RuntimeWarning: coroutine 'fetch_website_playwright' was never awaited\n",
      "  content = await fetch_website_playwright(url)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooksBaisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
